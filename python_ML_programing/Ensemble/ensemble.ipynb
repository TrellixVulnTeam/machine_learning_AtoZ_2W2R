{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "custom_style = {'axes.labelcolor': 'white',\n",
    "                'xtick.color': 'white',\n",
    "                'ytick.color': 'white'}\n",
    "sns.set_style(\"darkgrid\", rc=custom_style)\n",
    "sns.set_context(\"notebook\")\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, classifiers, vote='classlabel', weights=None):\n",
    "        self.classifiers = classifiers\n",
    "        self.name_classifiers = {key: value for key, value\n",
    "                                 in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #LabelEncoder を使ってクラスラベルが0から始まるようにエンコードする\n",
    "        #self.predictのnp.argmax呼び出しで重要となる\n",
    "        self.labelenc_ = LabelEncoder()\n",
    "        self.labelenc_.fit(y)\n",
    "        self.classes_ = self.labelenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X, self.labelenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:\n",
    "            predictions = np.asarray([clf.predict(X) for clf in self.classifiers_]).T\n",
    "            # 各サンプルのクラス確率に重みをかけて足し合わせた値が最大となる\n",
    "            # 列番号を配列として返す\n",
    "            maj_vote = np.apply_along_axis(lambda x:\n",
    "                                           np.argmax(np.bincount(x, weights=self.weights)),\n",
    "                                           axis=1,\n",
    "                                           arr=predictions)\n",
    "        # 各サンプルに確率の最大値を与えるクラスラベルを抽出\n",
    "        maj_vote = self.labelenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = np.asarray([clf.predict_proba(X) for clf in self.classifiers_ ])\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.name_classifiers.copy()\n",
    "            for name, step in six.iteritems(self.name_classifiers):\n",
    "                for key, value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s_%s'%(name, key)] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[50:,[1,2]], iris.target[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_a - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state = 1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation: ¥n\n",
      "ROC AUC: 0.87 (+/- 0.17) [Logistic regression]\n",
      "ROC AUC: 0.89 (+/- 0.16) [Decision tree]\n",
      "ROC AUC: 0.88 (+/- 0.15) [KNN]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(penalty='l2', C=0.001, random_state=1)\n",
    "clf2 = DecisionTreeClassifier(max_depth=1, criterion='entropy',random_state=0)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
    "pipe1 = Pipeline([['sc', StandardScaler()], ['clf', clf1]])\n",
    "pipe3 = Pipeline([['sc', StandardScaler()], ['clf', clf3]])\n",
    "clf_labels = ['Logistic regression', 'Decision tree', 'KNN']\n",
    "print('10-fold cross validation: ¥n')\n",
    "for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf, X=X_train, y=y_train,\n",
    "                            cv=10, scoring='roc_auc')\n",
    "    print('ROC AUC: %0.2f (+/- %0.2f) [%s]'%(scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf = MajorityVoteClassifier(classifiers=[pipe1, clf2, pipe3])\n",
    "clf_labels += ['Majority voting']\n",
    "all_clf = [pipe1, clf2, pipe3, mv_clf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.50594038 0.49405962]\n",
      "  [0.49977475 0.50022525]\n",
      "  [0.49419935 0.50580065]\n",
      "  [0.49671018 0.50328982]\n",
      "  [0.50738072 0.49261928]\n",
      "  [0.50088188 0.49911812]]\n",
      "\n",
      " [[0.91304348 0.08695652]\n",
      "  [0.04761905 0.95238095]\n",
      "  [0.04761905 0.95238095]\n",
      "  [0.04761905 0.95238095]\n",
      "  [0.91304348 0.08695652]\n",
      "  [0.91304348 0.08695652]]\n",
      "\n",
      " [[1.         0.        ]\n",
      "  [0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]]\n",
      "[[[0.49612677 0.50387323]\n",
      "  [0.49913759 0.50086241]\n",
      "  [0.50379832 0.49620168]\n",
      "  [0.50290337 0.49709663]\n",
      "  [0.50756363 0.49243637]\n",
      "  [0.5015891  0.4984109 ]]\n",
      "\n",
      " [[0.04761905 0.95238095]\n",
      "  [0.04761905 0.95238095]\n",
      "  [0.04761905 0.95238095]\n",
      "  [0.91304348 0.08695652]\n",
      "  [0.91304348 0.08695652]\n",
      "  [0.91304348 0.08695652]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]]\n",
      "[[[0.49941775 0.50058225]\n",
      "  [0.5034838  0.4965162 ]\n",
      "  [0.49776182 0.50223818]\n",
      "  [0.49932236 0.50067764]\n",
      "  [0.50897092 0.49102908]\n",
      "  [0.49913159 0.50086841]]\n",
      "\n",
      " [[0.04545455 0.95454545]\n",
      "  [0.95454545 0.04545455]\n",
      "  [0.04545455 0.95454545]\n",
      "  [0.95454545 0.04545455]\n",
      "  [0.95454545 0.04545455]\n",
      "  [0.95454545 0.04545455]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]]\n",
      "[[[0.48768387 0.51231613]\n",
      "  [0.49545425 0.50454575]\n",
      "  [0.49492298 0.50507702]\n",
      "  [0.50045514 0.49954486]\n",
      "  [0.50268441 0.49731559]\n",
      "  [0.505664   0.494336  ]]\n",
      "\n",
      " [[0.12       0.88      ]\n",
      "  [0.12       0.88      ]\n",
      "  [0.12       0.88      ]\n",
      "  [0.12       0.88      ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]]\n",
      "[[[0.49992372 0.50007628]\n",
      "  [0.50156358 0.49843642]\n",
      "  [0.49983741 0.50016259]\n",
      "  [0.49878252 0.50121748]\n",
      "  [0.50209102 0.49790898]\n",
      "  [0.5046418  0.4953582 ]]\n",
      "\n",
      " [[0.04347826 0.95652174]\n",
      "  [0.04347826 0.95652174]\n",
      "  [1.         0.        ]\n",
      "  [0.04347826 0.95652174]\n",
      "  [0.04347826 0.95652174]\n",
      "  [1.         0.        ]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [1.         0.        ]]]\n",
      "[[[0.501341   0.498659  ]\n",
      "  [0.48316025 0.51683975]\n",
      "  [0.49807356 0.50192644]\n",
      "  [0.5004533  0.4995467 ]]\n",
      "\n",
      " [[0.11538462 0.88461538]\n",
      "  [0.11538462 0.88461538]\n",
      "  [0.11538462 0.88461538]\n",
      "  [1.         0.        ]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [0.         1.        ]]]\n",
      "[[[0.49348286 0.50651714]\n",
      "  [0.49375524 0.50624476]\n",
      "  [0.50367074 0.49632926]\n",
      "  [0.50908783 0.49091217]]\n",
      "\n",
      " [[0.04545455 0.95454545]\n",
      "  [0.04545455 0.95454545]\n",
      "  [0.91666667 0.08333333]\n",
      "  [0.91666667 0.08333333]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]]\n",
      "[[[0.49445097 0.50554903]\n",
      "  [0.49735731 0.50264269]\n",
      "  [0.50655872 0.49344128]\n",
      "  [0.50518817 0.49481183]]\n",
      "\n",
      " [[0.04545455 0.95454545]\n",
      "  [0.04545455 0.95454545]\n",
      "  [0.91666667 0.08333333]\n",
      "  [0.91666667 0.08333333]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]]\n",
      "[[[0.49904562 0.50095438]\n",
      "  [0.48956223 0.51043777]\n",
      "  [0.50399299 0.49600701]\n",
      "  [0.50520583 0.49479417]]\n",
      "\n",
      " [[0.04545455 0.95454545]\n",
      "  [0.04545455 0.95454545]\n",
      "  [0.91666667 0.08333333]\n",
      "  [0.91666667 0.08333333]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]]\n",
      "[[[0.49245984 0.50754016]\n",
      "  [0.49325182 0.50674818]\n",
      "  [0.5126458  0.4873542 ]\n",
      "  [0.49991087 0.50008913]]\n",
      "\n",
      " [[0.04545455 0.95454545]\n",
      "  [0.04545455 0.95454545]\n",
      "  [0.91666667 0.08333333]\n",
      "  [0.91666667 0.08333333]]\n",
      "\n",
      " [[0.         1.        ]\n",
      "  [0.         1.        ]\n",
      "  [1.         0.        ]\n",
      "  [1.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(estimator=mv_clf, X=X_train, y=y_train,\n",
    "                            cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87 (+/- 0.17) [Logistic regression]\n",
      "ROC AUC: 0.89 (+/- 0.16) [Decision tree]\n",
      "ROC AUC: 0.88 (+/- 0.15) [KNN]\n",
      "ROC AUC: 0.94 (+/- 0.13) [Majority voting]\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf, X=X_train, y=y_train,\n",
    "                            cv=10, scoring='roc_auc')\n",
    "    print('ROC AUC: %0.2f (+/- %0.2f) [%s]'%(scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, classifiers, vote='classlabel', weights=None):\n",
    "        self.classifiers = classifiers\n",
    "        self.name_classifiers = {key: value for key, value\n",
    "                                 in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #LabelEncoder を使ってクラスラベルが0から始まるようにエンコードする\n",
    "        #self.predictのnp.argmax呼び出しで重要となる\n",
    "        self.labelenc_ = LabelEncoder()\n",
    "        self.labelenc_.fit(y)\n",
    "        self.classes_ = self.labelenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X, self.labelenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
    "            print('1')\n",
    "        else:\n",
    "            print('2')\n",
    "            predictions = np.asarray([clf.predict(X) for clf in self.classifiers_]).T\n",
    "            self.predictions_ = predictions\n",
    "            # 各サンプルのクラス確率に重みをかけて足し合わせた値が最大となる\n",
    "            # 列番号を配列として返す\n",
    "            maj_vote = np.apply_along_axis(lambda x:\n",
    "                                           np.argmax(np.bincount(x, weights=self.weights)),\n",
    "                                           axis=1,\n",
    "                                           arr=predictions)\n",
    "        # 各サンプルに確率の最大値を与えるクラスラベルを抽出\n",
    "        maj_vote = self.labelenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = np.asarray([clf.predict_proba(X) for clf in self.classifiers_ ])\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.name_classifiers.copy()\n",
    "            for name, step in six.iteritems(self.name_classifiers):\n",
    "                for key, value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s_%s'%(name, key)] = value\n",
    "            return out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
